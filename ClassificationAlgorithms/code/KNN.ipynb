{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the K value: 5\n",
      "enter filename along with the relative path: project3_dataset1.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import sys\n",
    "k = int(input(\"Enter the K value: \"))\n",
    "filename = input(\"enter filename along with the relative path: \")\n",
    "# filename = \"project3_dataset2.txt\"\n",
    "data = []\n",
    "for i in open(filename, 'r').readlines():\n",
    "        data.append(i.rstrip().split())    \n",
    "data = np.array(data)\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isString(data):\n",
    "    try:\n",
    "        float(data)\n",
    "        return False\n",
    "    except:\n",
    "        pass\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideandis(a, b):\n",
    "    dist = []\n",
    "    for i in range(len(a)):\n",
    "        if (isString(a[i])):\n",
    "            if (a[i] == b[i]):\n",
    "                dist.append(0)\n",
    "            else:\n",
    "                dist.append(1)\n",
    "        else:\n",
    "            dist.append(eval(a[i]) - eval(b[i]))\n",
    "    sqt = np.square(np.array(dist))\n",
    "    sqtsum = sqt.sum()\n",
    "    finaldist = sqtsum**(0.5)\n",
    "    return finaldist\n",
    "def KNN(tdata, vdata, tdataLabels, K):\n",
    "    predicLabels = []\n",
    "    for v in vdata:\n",
    "        dist = []\n",
    "        for t in tdata:\n",
    "            dist.append(euclideandis(v, t))\n",
    "        dist = np.array(dist).argsort()[:K]\n",
    "        temp = []\n",
    "        for ind in dist:\n",
    "            temp.append(tdataLabels[ind][0])\n",
    "        countDict = collections.Counter(temp)\n",
    "        predicLabels.append(countDict.most_common()[0][0])\n",
    "    return predicLabels         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(predictedLabels,trueLabels):\n",
    "    a=0\n",
    "    b=0\n",
    "    c=0\n",
    "    d=0\n",
    "    for i, j in zip(trueLabels,predictedLabels):\n",
    "            if ((j == 1) & (i == j)):\n",
    "                a += 1\n",
    "            elif ((j == 0) & (i != j)):\n",
    "                b += 1\n",
    "            elif ((j == 1) & (i != j)):\n",
    "                c += 1\n",
    "            elif ((j == 0) & (i == j)):\n",
    "                d += 1\n",
    "    sum = a+b+c+d\n",
    "    if sum == 0:\n",
    "        accuracy = \"Not possible to compute\"\n",
    "    else:\n",
    "        accuracy = (a+d)/sum\n",
    "    if a+c == 0:\n",
    "        precision = \"Not possible to compute\"\n",
    "    else:\n",
    "        precision = a/(a+c)\n",
    "    if a+b == 0:\n",
    "        recall = \"Not possible to compute\"\n",
    "    else:\n",
    "        recall = a/(a+b)\n",
    "    if a+b+c == 0:\n",
    "        f1 = \"Not possible to compute\"\n",
    "    else:\n",
    "        f1 = 2*a/(2*a+b+c)\n",
    "    return accuracy,precision,recall,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0\n",
      "Training data Length: 513\n",
      "Validation data Length: 56\n",
      "accuracy 0.8928571428571429\n",
      "precision 0.85\n",
      "recall 0.85\n",
      "f1 0.85\n",
      "\n",
      "Iteration 1\n",
      "Training data Length: 512\n",
      "Validation data Length: 57\n",
      "accuracy 0.9122807017543859\n",
      "precision 0.9523809523809523\n",
      "recall 0.8333333333333334\n",
      "f1 0.8888888888888888\n",
      "\n",
      "Iteration 2\n",
      "Training data Length: 512\n",
      "Validation data Length: 57\n",
      "accuracy 0.9122807017543859\n",
      "precision 1.0\n",
      "recall 0.8387096774193549\n",
      "f1 0.9122807017543859\n",
      "\n",
      "Iteration 3\n",
      "Training data Length: 512\n",
      "Validation data Length: 57\n",
      "accuracy 0.9298245614035088\n",
      "precision 0.85\n",
      "recall 0.9444444444444444\n",
      "f1 0.8947368421052632\n",
      "\n",
      "Iteration 4\n",
      "Training data Length: 512\n",
      "Validation data Length: 57\n",
      "accuracy 0.9649122807017544\n",
      "precision 1.0\n",
      "recall 0.8888888888888888\n",
      "f1 0.9411764705882353\n",
      "\n",
      "Iteration 5\n",
      "Training data Length: 512\n",
      "Validation data Length: 57\n",
      "accuracy 0.9649122807017544\n",
      "precision 0.9473684210526315\n",
      "recall 0.9473684210526315\n",
      "f1 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "randomdata = np.random.permutation(len(data))\n",
    "length = len(randomdata)\n",
    "Allaccuracies = []\n",
    "Allprecision = []\n",
    "Allrecall =[]\n",
    "Allf1score = []\n",
    "for i in range(10):\n",
    "    tdata = []\n",
    "    tdataLabels = []\n",
    "    vdata = []\n",
    "    vdataLabels = []\n",
    "    start = i *length//10\n",
    "    end = (i+1)*length//10\n",
    "    for j in range(length):\n",
    "        if(j in range(start,end)):\n",
    "            vdata.append(data[randomdata[j]][:-1])\n",
    "            vdataLabels.append(data[randomdata[j]][-1])\n",
    "        else:\n",
    "            tdata.append(data[randomdata[j]][:-1])\n",
    "            tdataLabels.append(data[randomdata[j]][-1])\n",
    "    tdata = np.array(tdata)\n",
    "    vdata = np.array(vdata)\n",
    "    predictedLabels  = np.array(KNN(tdata,vdata,tdataLabels,15)).astype(int)\n",
    "    actualLabels = np.array(vdataLabels).astype(int)\n",
    "#     print(predictedLabels,actualLabels)\n",
    "    accuracy,precision,recall,f1 = metrics(predictedLabels,actualLabels )\n",
    "#     print(precision)\n",
    "    if not (isString(accuracy)):\n",
    "        Allaccuracies.append(accuracy)\n",
    "    if not (isString(precision)):\n",
    "        Allprecision.append(precision)\n",
    "    if not (isString(recall)):\n",
    "        Allrecall.append(recall)\n",
    "    if not (isString(f1)):\n",
    "        Allf1score.append(f1)\n",
    "    print(\"\\nIteration \" + str(i))\n",
    "    print(\"Training data Length: \" + str(len(tdata)))\n",
    "    print(\"Validation data Length: \" + str(len(vdata)))\n",
    "    print(\"accuracy \" + str(accuracy))\n",
    "    print(\"precision \" + str(precision))\n",
    "    print(\"recall \" + str(recall))\n",
    "    print(\"f1 \" + str(f1))\n",
    "print(\"\\nAverageaccuracy \" + str(np.array(Allaccuracies).mean()))\n",
    "print(\"Averageprecision \" + str(np.array(Allprecision).mean()))\n",
    "print(\"Averagerecall \" + str(np.array(Allrecall).mean()))\n",
    "print(\"Averagef1 \" + str(np.array(Allf1score).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
