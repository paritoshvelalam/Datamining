{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted labels with k =  1\n",
      "predicted labels with k =  2\n",
      "predicted labels with k =  3\n",
      "predicted labels with k =  4\n",
      "predicted labels with k =  5\n",
      "predicted labels with k =  6\n",
      "predicted labels with k =  7\n",
      "predicted labels with k =  8\n",
      "predicted labels with k =  9\n",
      "predicted labels with k =  10\n",
      "predicted labels with k =  11\n",
      "predicted labels with k =  12\n",
      "predicted labels with k =  13\n",
      "predicted labels with k =  14\n",
      "predicted labels with k =  15\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import collections\n",
    "def loadCSV(filename): \n",
    "    ''' \n",
    "    function to load dataset \n",
    "    '''\n",
    "    with open(filename,\"r\") as csvfile: \n",
    "        lines = csv.reader(csvfile) \n",
    "        dataset = list(lines) \n",
    "        for i in range(len(dataset)): \n",
    "            dataset[i] = [float(x) for x in dataset[i]]      \n",
    "    return np.array(dataset)\n",
    "def isString(data):\n",
    "    try:\n",
    "        float(data)\n",
    "        return False\n",
    "    except:\n",
    "        pass\n",
    "        return True\n",
    "def euclideandis(a, b):\n",
    "    dist = []\n",
    "    for i in range(len(a)):\n",
    "        if (isString(a[i])):\n",
    "            if (a[i] == b[i]):\n",
    "                dist.append(0)\n",
    "            else:\n",
    "                dist.append(1)\n",
    "        else:\n",
    "#             print(a[i],b[i])\n",
    "            dist.append(a[i] - b[i])\n",
    "    sqt = np.square(np.array(dist))\n",
    "    sqtsum = sqt.sum()\n",
    "    finaldist = sqtsum**(0.5)\n",
    "    return finaldist\n",
    "def KNN(tdata, vdata, tdataLabels, K):\n",
    "    predicLabels = []\n",
    "    for v in vdata:\n",
    "        dist = []\n",
    "        for t in tdata:\n",
    "            dist.append(euclideandis(v, t))\n",
    "        dist = np.array(dist).argsort()[:K]\n",
    "        temp = []\n",
    "        for ind in dist:\n",
    "            temp.append(tdataLabels[ind][0])\n",
    "        countDict = collections.Counter(temp)\n",
    "        predicLabels.append(countDict.most_common()[0][0])\n",
    "    return predicLabels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tdata = loadCSV(r'C:\\Users\\sampr\\Documents\\dataMining\\Project3\\cse-601-project-3-fall-2019\\train_features.csv')\n",
    "tlabels = loadCSV(r'C:\\Users\\sampr\\Documents\\dataMining\\Project3\\cse-601-project-3-fall-2019\\train_label.csv')\n",
    "vdata = loadCSV(r'C:\\Users\\sampr\\Documents\\dataMining\\Project3\\cse-601-project-3-fall-2019\\test_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculating the optimal k an dpredicting values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxAcc = 0\n",
    "k = 0\n",
    "for i in range(1,16):\n",
    "    acc = kfold(tdata)\n",
    "    print(\"predicted labels with k = \" ,i, acc)\n",
    "    if(acc > maxAcc):\n",
    "        maxACC =acc\n",
    "        k= i\n",
    "predictedLabels  = np.array(KNN(tdata,vdata,tlabels,k)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(predictedLabels,trueLabels):\n",
    "    a=0\n",
    "    b=0\n",
    "    c=0\n",
    "    d=0\n",
    "    for i, j in zip(trueLabels,predictedLabels):\n",
    "            if ((j == 1) & (i == j)):\n",
    "                a += 1\n",
    "            elif ((j == 0) & (i != j)):\n",
    "                b += 1\n",
    "            elif ((j == 1) & (i != j)):\n",
    "                c += 1\n",
    "            elif ((j == 0) & (i == j)):\n",
    "                d += 1\n",
    "    sum = a+b+c+d\n",
    "    if sum == 0:\n",
    "        accuracy = \"Not possible to compute\"\n",
    "    else:\n",
    "        accuracy = (a+d)/sum\n",
    "    if a+c == 0:\n",
    "        precision = \"Not possible to compute\"\n",
    "    else:\n",
    "        precision = a/(a+c)\n",
    "    if a+b == 0:\n",
    "        recall = \"Not possible to compute\"\n",
    "    else:\n",
    "        recall = a/(a+b)\n",
    "    if a+b+c == 0:\n",
    "        f1 = \"Not possible to compute\"\n",
    "    else:\n",
    "        f1 = 2*a/(2*a+b+c)\n",
    "    return accuracy,precision,recall,f1\n",
    "def kfold(data):\n",
    "    randomdata = np.random.permutation(len(data))\n",
    "    length = len(randomdata)\n",
    "    Allaccuracies = []\n",
    "    Allprecision = []\n",
    "    Allrecall =[]\n",
    "    Allf1score = []\n",
    "    for i in range(10):\n",
    "        tdata = []\n",
    "        tdataLabels = []\n",
    "        vdata = []\n",
    "        vdataLabels = []\n",
    "        start = i *length//10\n",
    "        end = (i+1)*length//10\n",
    "        for j in range(length):\n",
    "            if(j in range(start,end)):\n",
    "                vdata.append(data[randomdata[j]][:-1])\n",
    "                vdataLabels.append(data[randomdata[j]][-1])\n",
    "            else:\n",
    "                tdata.append(data[randomdata[j]][:-1])\n",
    "                tdataLabels.append(data[randomdata[j]][-1])\n",
    "        tdata = np.array(tdata)\n",
    "        vdata = np.array(vdata)\n",
    "        predictedLabels  = np.array(KNN(tdata,vdata,tdataLabels,15)).astype(int)\n",
    "        actualLabels = np.array(vdataLabels).astype(int)\n",
    "    #     print(predictedLabels,actualLabels)\n",
    "        accuracy,precision,recall,f1 = metrics(predictedLabels,actualLabels )\n",
    "    #     print(precision)\n",
    "        if not (isString(accuracy)):\n",
    "            Allaccuracies.append(accuracy)\n",
    "        if not (isString(precision)):\n",
    "            Allprecision.append(precision)\n",
    "        if not (isString(recall)):\n",
    "            Allrecall.append(recall)\n",
    "        if not (isString(f1)):\n",
    "            Allf1score.append(f1)\n",
    "        print(\"\\nIteration \" + str(i))\n",
    "        print(\"Training data Length: \" + str(len(tdata)))\n",
    "        print(\"Validation data Length: \" + str(len(vdata)))\n",
    "        print(\"accuracy \" + str(accuracy))\n",
    "        print(\"precision \" + str(precision))\n",
    "        print(\"recall \" + str(recall))\n",
    "        print(\"f1 \" + str(f1))\n",
    "    print(\"\\nAverageaccuracy \" + str(np.array(Allaccuracies).mean()))\n",
    "    print(\"Averageprecision \" + str(np.array(Allprecision).mean()))\n",
    "    print(\"Averagerecall \" + str(np.array(Allrecall).mean()))\n",
    "    print(\"Averagef1 \" + str(np.array(Allf1score).mean()))\n",
    "    return np.array(Allaccuracies).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoosting Sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tdata = loadCSV(r'C:\\Users\\sampr\\Documents\\dataMining\\Project3\\cse-601-project-3-fall-2019\\train_features.csv')\n",
    "tlabels = loadCSV(r'C:\\Users\\sampr\\Documents\\dataMining\\Project3\\cse-601-project-3-fall-2019\\train_label.csv')\n",
    "vdata = loadCSV(r'C:\\Users\\sampr\\Documents\\dataMining\\Project3\\cse-601-project-3-fall-2019\\test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=200\n",
    ")\n",
    "classifier.fit(tdata, tlabels)\n",
    "predictions = classifier.predict(vdata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
