{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isString(data):\n",
    "    try:\n",
    "        float(data)\n",
    "        return False\n",
    "    except:\n",
    "        pass\n",
    "        return True\n",
    "def gini_index(groups, classes):\n",
    "    total_rows = 0.0;\n",
    "    for grp in groups:\n",
    "        total_rows += len(grp)\n",
    "        \n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        for val in classes:\n",
    "            count = 0\n",
    "            for row in group:\n",
    "                if(row[-1] == val):\n",
    "                    count = count+1;\n",
    "            proportion = count/size   \n",
    "            score += proportion * proportion\n",
    "        gini += (1.0 - score) * (size / total_rows)\n",
    "    return gini\n",
    "def splitData(data, value, ind):\n",
    "    left =[]\n",
    "    right = []\n",
    "    for row in data:\n",
    "        if(row[ind] >= value):\n",
    "            right.append(row)\n",
    "        else:\n",
    "            left.append(row)\n",
    "    return np.array(left), np.array(right)\n",
    "def evalSplitForest(data, num_features):\n",
    "    classes = np.unique(data[:,-1])\n",
    "    split_Ind, split_Val, Split_Data, minscore = 9999999, 9999999, None, 9999999\n",
    "    sample_features = []\n",
    "    d ={}\n",
    "    while len(sample_features) < num_features:\n",
    "        ind = random.randrange(len(data[0])-1)\n",
    "        if ind not in sample_features:\n",
    "            sample_features.append(ind)\n",
    "        \n",
    "    for col in sample_features:\n",
    "        for row in data:\n",
    "            samples =[]\n",
    "            left , right = splitData(data, row[ind], ind)\n",
    "            samples.append(left)\n",
    "            samples.append(right)\n",
    "            giniScore = gini_index(samples, classes)\n",
    "            if(giniScore<minscore):\n",
    "                split_Ind, split_Val, Split_Data, minscore = ind, row[ind], samples, giniScore\n",
    "    d['index'] = split_Ind\n",
    "    d['val'] = split_Val\n",
    "    d['sample'] = Split_Data\n",
    "    d['score'] = minscore\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitNodeForest(node , num_features):\n",
    "    left, right = node['sample']\n",
    "    \n",
    "    if((left.size==0) or (right.size==0)):\n",
    "        classes = []\n",
    "        if(left.size==0):\n",
    "            classes = right[:,-1]  \n",
    "        else:\n",
    "            classes = left[:,-1]\n",
    "        labelCount  = collections.Counter(classes)\n",
    "        top = labelCount.most_common()\n",
    "        node['left'] = node['right'] = top[0][0]\n",
    "        return\n",
    "    \n",
    "    if (len(left)<=1):\n",
    "        classes = left[:,-1]\n",
    "        labelCount  = collections.Counter(classes)\n",
    "        top = labelCount.most_common()\n",
    "        node['left'] = top[0][0]\n",
    "    else:\n",
    "        node['left'] = evalSplitForest(left, num_features)\n",
    "        splitNodeForest(node['left'],num_features)\n",
    "    \n",
    "    if(len(right)<=1):\n",
    "        classes = right[:,-1]\n",
    "        labelCount  = collections.Counter(classes)\n",
    "        top = labelCount.most_common()\n",
    "        node['right'] = top[0][0]\n",
    "    else:\n",
    "        node['right'] = evalSplitForest(right, num_features)\n",
    "        splitNodeForest(node['right'],num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(node, row):\n",
    "    if row[node['index']] < node['val']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(predictedLabels,trueLabels):\n",
    "    a=0\n",
    "    b=0\n",
    "    c=0\n",
    "    d=0\n",
    "    for i, j in zip(trueLabels,predictedLabels):\n",
    "            if ((j == 1) & (i == j)):\n",
    "                a += 1\n",
    "            elif ((j == 0) & (i != j)):\n",
    "                b += 1\n",
    "            elif ((j == 1) & (i != j)):\n",
    "                c += 1\n",
    "            elif ((j == 0) & (i == j)):\n",
    "                d += 1\n",
    "    sum = a+b+c+d\n",
    "    if sum == 0:\n",
    "        accuracy = \"Not possible to compute\"\n",
    "    else:\n",
    "        accuracy = (a+d)/sum\n",
    "    if a+c == 0:\n",
    "        precision = \"Not possible to compute\"\n",
    "    else:\n",
    "        precision = a/(a+c)\n",
    "    if a+b == 0:\n",
    "        recall = \"Not possible to compute\"\n",
    "    else:\n",
    "        recall = a/(a+b)\n",
    "    if a+b+c == 0:\n",
    "        f1 = \"Not possible to compute\"\n",
    "    else:\n",
    "        f1 = 2*a/(2*a+b+c)\n",
    "    return accuracy,precision,recall,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as random\n",
    "def randomForest(traindata, testdata, num_trees, num_features ):\n",
    "    forest_List = []\n",
    "    predicted_List = []\n",
    "    sample_size = int(len(traindata)/num_trees)\n",
    "    for i in range(0, num_trees):\n",
    "        sample = []\n",
    "        while(len(sample)<sample_size):\n",
    "            i = random.randrange(len(traindata))\n",
    "            sample.append(traindata[i])\n",
    "        sample = np.array(sample)\n",
    "        root = evalSplitForest(sample, num_features)\n",
    "        splitNodeForest(root, num_features)\n",
    "        forest_List.append(root)\n",
    "\n",
    "    for row in testdata:\n",
    "        row_prediction = []\n",
    "        for tree in forest_List:\n",
    "            row_prediction.append(predict(tree, row))\n",
    "        countDict = collections.Counter(row_prediction)\n",
    "        predicted_List.append(countDict.most_common()[0][0])\n",
    "\n",
    "    actual_List = list(testdata[:,-1])\n",
    "    return actual_List, predicted_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter no of trees: 5\n",
      "Enter no of features: 10\n",
      "\n",
      "Iteration 0\n",
      "Training data Length: 513\n",
      "Validation data Length: 56\n",
      "accuracy 0.9107142857142857\n",
      "precision 0.8636363636363636\n",
      "recall 0.9047619047619048\n",
      "f1 0.8837209302325582\n",
      "\n",
      "Iteration 1\n",
      "Training data Length: 512\n",
      "Validation data Length: 57\n",
      "accuracy 0.8245614035087719\n",
      "precision 0.782608695652174\n",
      "recall 0.782608695652174\n",
      "f1 0.782608695652174\n",
      "\n",
      "Iteration 2\n",
      "Training data Length: 512\n",
      "Validation data Length: 57\n",
      "accuracy 0.9824561403508771\n",
      "precision 1.0\n",
      "recall 0.9473684210526315\n",
      "f1 0.972972972972973\n",
      "\n",
      "Iteration 3\n",
      "Training data Length: 512\n",
      "Validation data Length: 57\n",
      "accuracy 0.9649122807017544\n",
      "precision 0.9375\n",
      "recall 0.9375\n",
      "f1 0.9375\n",
      "\n",
      "Iteration 4\n",
      "Training data Length: 512\n",
      "Validation data Length: 57\n",
      "accuracy 0.9122807017543859\n",
      "precision 0.9411764705882353\n",
      "recall 0.8\n",
      "f1 0.8648648648648649\n",
      "\n",
      "Iteration 5\n",
      "Training data Length: 512\n",
      "Validation data Length: 57\n",
      "accuracy 0.9473684210526315\n",
      "precision 0.9523809523809523\n",
      "recall 0.9090909090909091\n",
      "f1 0.9302325581395349\n",
      "\n",
      "Iteration 6\n",
      "Training data Length: 512\n",
      "Validation data Length: 57\n",
      "accuracy 0.9122807017543859\n",
      "precision 0.92\n",
      "recall 0.8846153846153846\n",
      "f1 0.9019607843137255\n",
      "\n",
      "Iteration 7\n",
      "Training data Length: 512\n",
      "Validation data Length: 57\n",
      "accuracy 0.9298245614035088\n",
      "precision 0.9375\n",
      "recall 0.8333333333333334\n",
      "f1 0.8823529411764706\n",
      "\n",
      "Iteration 8\n",
      "Training data Length: 512\n",
      "Validation data Length: 57\n",
      "accuracy 0.9122807017543859\n",
      "precision 0.8888888888888888\n",
      "recall 0.9230769230769231\n",
      "f1 0.9056603773584906\n",
      "\n",
      "Iteration 9\n",
      "Training data Length: 512\n",
      "Validation data Length: 57\n",
      "accuracy 0.9122807017543859\n",
      "precision 0.9\n",
      "recall 0.8571428571428571\n",
      "f1 0.8780487804878049\n",
      "\n",
      "Averageaccuracy 0.9208959899749372\n",
      "Averageprecision 0.9123691371146615\n",
      "Averagerecall 0.8779498428726118\n",
      "Averagef1 0.8939922905198598\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import sys\n",
    "K = 10\n",
    "filename = input(\"enter file name with relative path: \")\n",
    "data = []\n",
    "for i in open(filename, 'r').readlines():\n",
    "        data.append(i.rstrip().split())    \n",
    "data = np.array(data);\n",
    "num_trees = int(input(\"Enter no of trees: \"))\n",
    "num_features = int(input(\"Enter no of features: \"))\n",
    "randomdata = np.random.permutation(len(data))\n",
    "length = len(randomdata)\n",
    "Allaccuracies = []\n",
    "Allprecision = []\n",
    "Allrecall =[]\n",
    "Allf1score = []\n",
    "length = len(randomdata)\n",
    "for i in range(K):\n",
    "    tdata = []\n",
    "    tdataLabels = []\n",
    "    vdata = []\n",
    "    vdataLabels = []\n",
    "    start = i *length//10\n",
    "    end = (i+1)*length//10\n",
    "    for j in range(length):\n",
    "        if(j in range(start,end)):\n",
    "            vdata.append(data[randomdata[j]])\n",
    "            vdataLabels.append(data[randomdata[j]][-1])\n",
    "        else:\n",
    "            tdata.append(data[randomdata[j]])\n",
    "            tdataLabels.append(data[randomdata[j]][-1])\n",
    "    tdata = np.array(tdata)\n",
    "    vdata = np.array(vdata)\n",
    "#     print(tdata.shape)\n",
    "    actualLabels, predictedLabels  = randomForest(tdata,vdata, num_trees, num_features)\n",
    "    actualLabels = np.array(actualLabels).astype(int)\n",
    "    predictedLabels = np.array(predictedLabels).astype(int)\n",
    "    accuracy,precision,recall,f1 = metrics(predictedLabels,actualLabels)\n",
    "    if not (isString(accuracy)):\n",
    "        Allaccuracies.append(accuracy)\n",
    "    if not (isString(precision)):\n",
    "        Allprecision.append(precision)\n",
    "    if not (isString(recall)):\n",
    "        Allrecall.append(recall)\n",
    "    if not (isString(f1)):\n",
    "        Allf1score.append(f1)\n",
    "    print(\"\\nIteration \" + str(i))\n",
    "    print(\"Training data Length: \" + str(len(tdata)))\n",
    "    print(\"Validation data Length: \" + str(len(vdata)))\n",
    "    print(\"accuracy \" + str(accuracy))\n",
    "    print(\"precision \" + str(precision))\n",
    "    print(\"recall \" + str(recall))\n",
    "    print(\"f1 \" + str(f1))\n",
    "print(\"\\nAverageaccuracy \" + str(np.array(Allaccuracies).mean()))\n",
    "print(\"Averageprecision \" + str(np.array(Allprecision).mean()))\n",
    "print(\"Averagerecall \" + str(np.array(Allrecall).mean()))\n",
    "print(\"Averagef1 \" + str(np.array(Allf1score).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import numpy as np\n",
    "# import collections\n",
    "# def loadCSV(filename): \n",
    "#     ''' \n",
    "#     function to load dataset \n",
    "#     '''\n",
    "#     with open(filename,\"r\") as csvfile: \n",
    "#         lines = csv.reader(csvfile) \n",
    "#         dataset = list(lines) \n",
    "#         for i in range(len(dataset)): \n",
    "#             dataset[i] = [float(x) for x in dataset[i]]      \n",
    "#     return np.array(dataset)\n",
    "# data = loadCSV(r'C:\\Users\\sampr\\Documents\\dataMining\\Project3\\cse-601-project-3-fall-2019\\train_features.csv')\n",
    "# data1 = loadCSV(r'C:\\Users\\sampr\\Documents\\dataMining\\Project3\\cse-601-project-3-fall-2019\\test_features.csv')\n",
    "# actualLabels, predictedLabels  = randomForest(data,data1, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s.to_csv(\"kaggle1.csv\", sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
